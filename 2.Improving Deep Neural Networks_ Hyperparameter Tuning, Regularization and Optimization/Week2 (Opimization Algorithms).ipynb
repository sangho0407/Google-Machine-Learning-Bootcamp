{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "142edce1",
   "metadata": {},
   "source": [
    "# Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27774604",
   "metadata": {},
   "source": [
    "큰 데이터셋에서 딥러닝을 훈련시킬 때, 전체 데이터셋을 한 번에 처리하기보다는 일부분씩 나누어 처리하는 것이 효율적일 수 있습니다. 이렇게 나눈 작은 데이터 묶음을 \"미니 배치\"라고 부릅니다.\n",
    "\n",
    "**미니 배치 경사하강법(Mini-batch Gradient Descent)**은 큰 데이터셋을 여러 개의 작은 '미니 배치'로 나누어 경사하강법을 적용하는 방법입니다.\n",
    "\n",
    "1. **미니 배치의 이해**: 만약 우리의 전체 트레이닝 셋에 5백만 개의 샘플이 있다면, 이것을 한 번에 처리하는 것은 매우 느릴 수 있습니다. 그래서 이를 예를 들면, 1,000개의 샘플로 나누어서 5,000개의 미니 배치로 만들 수 있습니다.\n",
    "\n",
    "2. **미니 배치 경사하강법의 동작**: 전체 데이터셋을 사용하여 한 번의 경사하강법 스텝을 수행하는 대신, 미니 배치를 사용하여 여러 번의 경사하강법 스텝을 수행합니다. 이 과정에서 각 미니 배치에 대해 순전파(forward propagation)와 역전파(back propagation)를 수행하여 가중치를 업데이트합니다.\n",
    "\n",
    "3. **에포크(Epoch)**: 전체 트레이닝 데이터셋을 한 번 통과하는 것을 에포크라고 합니다. 미니 배치 경사하강법에서는 한 번의 에포크 동안 여러 개의 경사하강법 스텝을 수행합니다.\n",
    "\n",
    "미니 배치 경사하강법의 장점은 큰 데이터셋에 대해 훨씬 빠른 수렴을 가능하게 합니다. 전체 데이터셋에 대해 경사하강법을 수행하는 것보다 각 미니 배치에 대해 여러 번의 업데이트를 수행함으로써 빠른 피드백을 받고, 가중치를 효율적으로 업데이트할 수 있습니다.\n",
    "\n",
    "단, 미니 배치 경사하강법의 수렴은 때로는 불안정 할 수 있으며, 좋은 미니 배치 크기나 학습률을 선택하는 것이 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6c155e",
   "metadata": {},
   "source": [
    "# Understanding Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef244dd",
   "metadata": {},
   "source": [
    "### 배치 경사 하강법 vs 미니-배치 경사 하강법\n",
    "* **배치 경사 하강법**: 모든 학습 데이터를 사용하여 한 번에 경사 하강법을 실행합니다. 이 방법은 각 반복마다 비용 함수가 감소하므로 안정적입니다. 그러나 대규모 데이터셋에서는 한 단계를 완료하는 데 시간이 오래 걸릴 수 있습니다.\n",
    "  \n",
    "* **미니-배치 경사 하강법**: 전체 데이터셋을 여러 미니-배치로 분할하여 각 미니-배치를 사용하여 경사 하강법을 실행합니다. 이는 전체 데이터셋을 처리하기 전에도 업데이트를 할 수 있게 해주므로, 학습 속도가 빠를 수 있습니다.\n",
    "\n",
    "### 미니-배치의 비용 그래프\n",
    "미니-배치 경사 하강법을 사용하면 비용 그래프가 더 불안정할 수 있습니다. 각 미니-배치마다 데이터 분포가 약간 다르기 때문에, 비용 함수가 항상 감소하는 것은 아닙니다. 그럼에도 불구하고 전반적인 추세는 비용이 감소하는 방향으로 나타나야 합니다.\n",
    "\n",
    "### 미니-배치 크기 선택\n",
    "* **배치 크기 = m**: 전체 데이터셋 크기와 같으면, 이것은 단순히 배치 경사 하강법입니다.\n",
    "  \n",
    "* **배치 크기 = 1**: 각 샘플을 독립적으로 처리하면 확률적 경사 하강법(Stochastic Gradient Descent, SGD)이 됩니다. 이 방법은 매우 노이즈가 많을 수 있습니다.\n",
    "\n",
    "실제로 가장 좋은 미니-배치 크기는 1과 m 사이입니다. 너무 큰 배치 크기는 한 번의 반복이 너무 오래 걸리게 만들고, 너무 작은 배치 크기는 벡터화의 장점을 잃게 만듭니다. 일반적으로 미니-배치 크기는 64, 128, 256, 512 등 2의 제곱을 사용하는 경우가 많습니다.\n",
    "\n",
    "### 활용 팁\n",
    "* 데이터셋이 작은 경우(예: 2000개 미만): 미니-배치를 사용하는 대신 전체 배치 경사 하강법을 사용합니다.\n",
    "  \n",
    "* 미니-배치 크기 선택: 학습 세트의 크기, 메모리 사용량, 벡터화 속도 등을 고려하여 최적의 크기를 선택합니다. 때로는 여러 가지 크기를 실험하여 가장 효과적인 것을 찾아야 할 수도 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "미니-배치 경사 하강법은 대규모 데이터셋에서 효율적인 학습을 가능하게 합니다. 하지만 그 자체로도 최적화할 수 있는 다양한 요소가 있으며, 다른 고급 최적화 기법들과 함께 사용될 때 더욱 효과적일 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c95f8",
   "metadata": {},
   "source": [
    "# Exponentially Weighted Averages & Understanding Exponentially Weighted Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5010b73c",
   "metadata": {},
   "source": [
    "\n",
    "### **지수 가중 평균 (Exponentially Weighted Averages)**\n",
    "1. **메모리 효율성**: 지수 가중 평균은 이전의 모든 데이터를 저장할 필요 없이 이전 평균만을 유지하면서 계산됩니다.\n",
    "2. **반응성**: $( \\beta $) 값에 따라 최근의 변화에 얼마나 빠르게 반응할 것인지 조절할 수 있습니다.\n",
    "3. **부드러운 곡선**: 데이터에 있는 노이즈나 진동을 줄여서 부드러운 곡선을 생성합니다.\n",
    "\n",
    "### **장점**\n",
    "1. **단순성**: 구현하기가 간단하며 연산량이 적습니다.\n",
    "2. **효율성**: 큰 데이터 세트에서도 잘 동작하며 메모리 효율이 좋습니다.\n",
    "3. **유연성**: $( \\beta $) 값을 조절하여 다양한 시나리오에 적응시킬 수 있습니다.\n",
    "\n",
    "### **동작 원리**\n",
    "지수 가중 평균은 이름에서 알 수 있듯이 가중치가 지수적으로 감소하는 방식으로 평균을 계산합니다. 이는 가장 최근의 데이터가 평균에 큰 영향을 미치고, 오래된 데이터는 점차 작은 영향을 미치도록 설계되었습니다.\n",
    "\n",
    "1. **초기화**: $( V_0 $)를 0으로 설정합니다.\n",
    "2. **가중치 업데이트**: 매일 다음과 같은 식을 사용하여 가중치를 업데이트합니다.\n",
    "$[ V_t = \\beta \\times V_{t-1} + (1-\\beta) \\times \\theta_t $]\n",
    "여기서 $( \\theta_t $)는 해당 날짜의 데이터입니다.\n",
    "\n",
    "이러한 방식으로 가장 최근의 데이터에 더 큰 가중치를 부여하고, 과거의 데이터에는 점점 더 작은 가중치를 부여합니다. $( \\beta $) 값은 이러한 가중치의 감소 속도를 조절합니다.\n",
    "\n",
    "**예시**: 작년의 런던 일일 온도\n",
    "\n",
    "데이터를 이해하기 위한 배경: \n",
    "- 작성자는 현재 미국에 거주하고 있지만 런던에서 태어났습니다.\n",
    "- 그는 런던의 작년 일일 온도를 예시로 사용하였습니다. \n",
    "- 예를 들어, 1월 1일 온도는 4도였고, 1월 2일은 9도였다.\n",
    "- 1년의 중간, 즉 5월 말경에는 15도였다.\n",
    "\n",
    "이렇게 데이터를 그래프로 그리면 노이즈가 많이 보이는데, 이를 좀 더 부드럽게 만들기 위해서 지수 가중 평균을 사용할 수 있습니다.\n",
    "\n",
    "### 지수 가중 평균 계산\n",
    "\n",
    "1. $( V_0 $) 를 0으로 초기화합니다.\n",
    "2. 매일 지수 가중 평균을 다음과 같은 식으로 계산합니다: \n",
    "$[ V_t = \\beta \\times V_{t-1} + (1-\\beta) \\times \\theta_t $]\n",
    "여기서 $( \\theta_t $) 는 그날의 온도입니다.\n",
    "\n",
    "기본적으로 이 식은 오늘의 평균 온도와 이전 날의 평균 온도를 결합하여 새로운 평균 온도를 생성합니다.\n",
    "\n",
    "### β의 역할\n",
    "\n",
    "β 값을 조정하면 평균의 \"부드러움\"이나 \"반응성\"이 변경됩니다. \n",
    "\n",
    "- $( \\beta = 0.9 $) 일 때, 약 10일 동안의 온도를 평균낸 것과 비슷합니다.\n",
    "- $( \\beta = 0.98 $) 일 때, 약 50일 동안의 온도를 평균낸 것과 비슷합니다. 그 결과로 훨씬 부드러운 곡선이 만들어집니다. 그러나, 최근의 변화에 더 느리게 반응합니다.\n",
    "- $( \\beta = 0.5 $) 일 때, 오직 2일 동안의 온도만을 평균낸 것과 비슷하므로, 노이즈가 많이 보이지만 최근의 변화에는 빠르게 반응합니다.\n",
    "\n",
    "결론적으로, 지수 가중 평균은 데이터의 부드러운 평균을 생성하기 위한 방법입니다. $( \\beta $) 값에 따라 평균의 부드러움과 반응성을 조절할 수 있습니다. 이러한 지수 가중 평균 방식은 추후 소개될 고급 최적화 알고리즘에서 중요한 역할을 합니다.\n",
    "\n",
    "---\n",
    "\n",
    "지수 가중 평균은 많은 시계열 데이터 분석에서 유용하게 사용되며, 특히 머신러닝의 최적화 알고리즘에서 그 중요성이 높아집니다. $( \\beta $)의 선택은 데이터의 특성 및 응용 분야에 따라 달라질 수 있으므로, 다양한 값을 실험하여 최적의 결과를 얻는 것이 중요합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a65a39",
   "metadata": {},
   "source": [
    "# Bias Correction in Exponentially Weighted Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d575d58",
   "metadata": {},
   "source": [
    "1. **지수 가중 평균의 문제점**:\n",
    "   - 베타가 0.98일 때, 기대한 초록색 곡선 대신 보라색 곡선이 나타난다.\n",
    "   - 이동 평균의 초기 단계에서 편향된 추정치가 나타난다.\n",
    "\n",
    "2. **원인**:\n",
    "   - V_0을 0으로 초기화 할 때, 초기 온도 추정치가 실제 온도보다 낮게 나타난다.\n",
    "   - 이는 V_1과 V_2 계산 과정에서 베타 값을 반영할 때 발생한다.\n",
    "\n",
    "3. **편향 보정 방법**:\n",
    "   - V_t 대신에 V_t를 \\(1 - \\beta^t\\)로 나눈다.\n",
    "   - 이렇게 하면 초기 추정치의 편향을 줄일 수 있다.\n",
    "\n",
    "4. **편향 보정의 효과**:\n",
    "   - t가 크면, 보정은 거의 차이를 만들지 않는다.\n",
    "   - 초록색 곡선과 보라색 곡선이 거의 겹치게 된다.\n",
    "\n",
    "5. **기계 학습에서의 적용**:\n",
    "   - 대부분의 지수 가중 평균 구현에서는 편향 보정을 자주 사용하지 않는다.\n",
    "   - 하지만 초기 단계의 편향에 대해 우려한다면 편향 보정을 사용하여 더 나은 추정치를 얻을 수 있다.\n",
    "\n",
    "6. **결론**:\n",
    "   - 지수 가중 이동 평균을 이해하고, 이를 활용하여 최적화 알고리즘을 개선할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c59de",
   "metadata": {},
   "source": [
    "# Gradient Descent with Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643fde3",
   "metadata": {},
   "source": [
    "### 1. **모멘텀의 개념**\n",
    "- 기본 아이디어: 기울기의 지수 가중 평균을 계산하고 해당 기울기로 가중치를 업데이트한다.\n",
    "- 표준 경사 하강법보다 대부분 빠르게 동작한다.\n",
    "\n",
    "### 2. **경사 하강법의 문제점**\n",
    "- 비용 함수의 등고선이 타원형태일 때, 경사 하강법은 최소값을 향해 진동하며 천천히 진행된다.\n",
    "- 너무 큰 학습률을 사용하면 발산할 수 있다.\n",
    "\n",
    "### 3. **모멘텀의 동작 방식**\n",
    "- 각 반복에서 일반적인 미분 dw, db를 계산한다.\n",
    "- vdW와 vdb의 지수 가중 평균을 계산한다.\n",
    "- 가중치는 vdW와 vdb를 사용하여 업데이트된다.\n",
    "\n",
    "### 4. **모멘텀의 효과**\n",
    "- 기울기의 특정 방향에 대한 진동을 줄여준다.\n",
    "- 수평 방향으로 더 빠르게 움직이게 해준다.\n",
    "\n",
    "### 5. **모멘텀에 대한 직관**\n",
    "- 공이 언덕을 내려올 때의 움직임에 비유할 수 있다.\n",
    "- 기울기는 가속도로, 모멘텀은 속도로 생각할 수 있다.\n",
    "\n",
    "### 6. **구현의 세부사항**\n",
    "- 학습률(α) 및 지수 가중 평균을 제어하는 파라미터(Beta)가 있음.\n",
    "- Beta의 일반적인 값은 0.9다.\n",
    "- 편향 보정은 일반적으로 사용되지 않는다.\n",
    "- 초기 vdW와 vdb는 0으로 초기화된다.\n",
    "\n",
    "### 7. **리터러처의 주의점**\n",
    "- 일부 문서에서는 1 - Beta 항이 생략되기도 한다.\n",
    "- 두 버전 모두 잘 작동하지만, α 학습률은 각각 다르게 조정될 필요가 있다.\n",
    "\n",
    "### 8. **결론**\n",
    "- 모멘텀을 사용하는 경사 하강법은 일반적으로 모멘텀이 없는 경사 하강법보다 더 좋다.\n",
    "- 학습 알고리즘을 더 빠르게 만들기 위한 다른 방법도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a69662c",
   "metadata": {},
   "source": [
    "# RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e187417",
   "metadata": {},
   "source": [
    "**1. RMSprop 알고리즘의 도입**\n",
    "   - **그래디언트 디센트의 문제점**: 높은 차원의 공간에서 그래디언트 디센트를 사용하면 큰 수직 방향의 진동이 발생할 수 있습니다.\n",
    "   - 이 문제를 해결하기 위해 RMSprop 알고리즘이 도입되었습니다.\n",
    "\n",
    "**2. RMSprop의 작동 원리**\n",
    "   - RMSprop은 미분 값의 제곱의 지수 가중치 평균을 저장합니다.\n",
    "   - 수식: \n",
    "     - $( SdW = \\beta SdW + (1-\\beta) dW^2 $)\n",
    "     - $( Sdb = \\beta Sdb + (1-\\beta) db^2 $)\n",
    "   - 그 다음, 파라미터를 다음과 같이 업데이트 합니다:\n",
    "     - $( W = W - \\alpha \\frac{dW}{\\sqrt{SdW}} $)\n",
    "     - $( b = b - \\alpha \\frac{db}{\\sqrt{Sdb}} $)\n",
    "\n",
    "**3. RMSprop의 직관**\n",
    "   - 수평 방향 (W 방향)에서는 학습이 빠르게 이루어져야 합니다.\n",
    "   - 수직 방향 (b 방향)에서는 진동을 줄이기 위해 학습을 느리게 해야 합니다.\n",
    "   - RMSprop는 이러한 목표를 달성하기 위해 사용됩니다.\n",
    "\n",
    "**4. RMSprop의 효과**\n",
    "   - 수직 방향의 업데이트는 큰 숫자로 나눠져서 진동이 감소하게 됩니다.\n",
    "   - 수평 방향의 업데이트는 작은 숫자로 나눠져서 빠르게 진행됩니다.\n",
    "\n",
    "**5. 기타 세부 사항**\n",
    "   - 알고리즘이 0으로 나누는 것을 방지하기 위해 매우 작은 값인 엡실론(epsilon)을 분모에 추가합니다.\n",
    "   - RMSprop는 코세라(Coursera) 강의에서 제프 힌튼(Jeff Hinton)에 의해 처음 제안되었습니다.\n",
    "\n",
    "**6. 다음 단계**\n",
    "   - 모멘텀과 RMSprop을 결합하면 더 나은 최적화 알고리즘이 만들어집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c35dcf",
   "metadata": {},
   "source": [
    "# Adam Optimization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dbc542",
   "metadata": {},
   "source": [
    "**1. 딥러닝 최적화 알고리즘의 역사**\n",
    "   - **초기 문제점**: 몇몇 유명한 연구자들이 최적화 알고리즘을 제안하였지만, 대부분은 다양한 신경망에서 잘 동작하지 않았다.\n",
    "   - **결과**: 이로 인해 딥러닝 커뮤니티에서는 새로운 최적화 알고리즘에 대한 회의적인 의견이 많았다.\n",
    "\n",
    "**2. Adam 최적화 알고리즘의 도입**\n",
    "   - **Adam의 장점**: 넓은 범위의 딥러닝 아키텍처에서 잘 동작하는 것으로 밝혀짐.\n",
    "   - **기본 원리**: 모멘텀과 RMSprop를 결합한 방식으로 동작.\n",
    "\n",
    "**3. Adam 알고리즘의 구현**\n",
    "   - **초기화**: \\( V_{dw} = 0, S_{dw} = 0 \\), \\( V_{db}, S_{db} = 0 \\)\n",
    "   - **반복시**: 미니배치를 사용하여 dw와 db를 계산.\n",
    "   - **모멘텀 업데이트**와 **RMSprop 업데이트**를 조합하여 파라미터를 업데이트.\n",
    "\n",
    "**4. Adam의 하이퍼파라미터**\n",
    "   - **α (학습률)**: 주요하게 조정되어야 하는 하이퍼파라미터.\n",
    "   - **β1**: 모멘텀 업데이트에 대한 가중치 (기본값 0.9).\n",
    "   - **β2**: RMSprop 업데이트에 대한 가중치 (기본값 0.999).\n",
    "   - **ε (엡실론)**: 나눗셈에서 0을 방지하기 위한 작은 상수 (기본값 \\(10^{-8}\\)).\n",
    "\n",
    "**5. Adam의 이름 유래**\n",
    "   - \"adaptive moment estimation\"의 약자.\n",
    "   - β1은 미분의 평균 (첫 번째 순간)을 계산하고, β2는 제곱의 지수 가중 평균 (두 번째 순간)을 계산.\n",
    "\n",
    "**6. 추가 사항**\n",
    "   - Adam 알고리즘과 관련된 이름 \"Adam Coates\"는 이 알고리즘과 관련이 없다.\n",
    "   - 다음 비디오에서는 학습률 감소에 대해 논의할 예정."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e81eda",
   "metadata": {},
   "source": [
    "# Learning Rate Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abdaab1",
   "metadata": {},
   "source": [
    "1. **학습률 감소의 필요성**\n",
    "   - 미니 배치 경사 하강법을 사용할 때 학습률이 고정되면, 알고리즘이 최솟값 주변을 무작위로 방황할 수 있습니다. 이는 미니 배치의 노이즈 때문입니다.\n",
    "   - 학습률을 점차 감소시키면 초기에는 큰 단계를 밟을 수 있지만, 학습이 수렴됨에 따라 작은 단계를 밟을 수 있게 됩니다.\n",
    "\n",
    "2. **학습률 감소 방법**\n",
    "   - **에포크 기반 감소**: 한 번의 전체 데이터 통과를 에포크라고 합니다. 학습률은 `α = 1 / (1 + 감소율 * 에포크 번호) * 초기 학습률 α0` 식으로 설정됩니다.\n",
    "   - **지수 감소**: `α = (0.95^에포크 번호) * α0`과 같은 형식을 사용하여 학습률이 지수적으로 감소합니다.\n",
    "   - **루트 기반 감소**: 학습률은 `α = k / sqrt(에포크 번호) * α0` 또는 `α = k / sqrt(미니 배치 번호) * α0`와 같은 형식으로 설정됩니다.\n",
    "   - **계단식 감소**: 일정 시간 동안 학습률을 일정하게 유지한 후, 이후에 학습률을 절반으로 줄입니다.\n",
    "\n",
    "3. **수동 감소**\n",
    "   - 모델 학습을 직접 관찰하면서 학습률을 수동으로 조절하는 방법입니다. 이 방법은 적은 수의 모델만 훈련할 때 유용합니다.\n",
    "\n",
    "4. **하이퍼파라미터 선택**\n",
    "   - 많은 하이퍼파라미터 중에서 선택해야 할 때는 학습률 감소가 다른 요소들보다 낮은 우선순위를 가질 수 있습니다. 하지만 시스템적인 방법으로 하이퍼파라미터를 선택하는 방법에 대해서는 추후에 더 자세히 알아볼 예정입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebea3ff",
   "metadata": {},
   "source": [
    "# The Problem of Local Optima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1dd00b",
   "metadata": {},
   "source": [
    "**로컬 옵티마(Local Optima)에 대한 오해**\n",
    "\n",
    "- 초기 딥러닝 시대에는 최적화 알고리즘이 나쁜 로컬 옵티마에서 멈추게 될 거라는 우려가 있었습니다.\n",
    "- 2차원 공간에서는 많은 로컬 옵티마를 가진 그림을 쉽게 생성할 수 있지만, 이것은 실제 딥러닝 네트워크의 동작과 일치하지 않습니다.\n",
    "\n",
    "**안장점(Saddle Points)**\n",
    "\n",
    "- 대부분의 0 기울기를 가진 지점은 로컬 옵티마가 아니라 안장점입니다.\n",
    "- 높은 차원의 함수에서는 기울기가 0인 모든 방향이 볼록(convex) 또는 오목(concave)한 형태를 가져야 로컬 옵티마가 됩니다.\n",
    "- 매우 높은 차원의 공간에서는 로컬 옵티마보다 안장점을 만날 가능성이 더 높습니다.\n",
    "\n",
    "**플래토(Plateaus) 문제**\n",
    "\n",
    "- 로컬 옵티마보다 플래토가 학습을 느리게 만드는 더 큰 문제입니다.\n",
    "- 기울기가 0 또는 근처인 곳에서는 경사 하강법이 매우 천천히 움직이게 되어 학습이 느려집니다.\n",
    "- 모멘텀, RmsProp, Adam과 같은 알고리즘이 이러한 문제를 해결하는 데 도움을 줄 수 있습니다.\n",
    "\n",
    "**결론**\n",
    "\n",
    "- 충분히 큰 신경망을 학습시키는 한, 나쁜 로컬 옵티마에 갇힐 가능성은 낮습니다.\n",
    "- 높은 차원의 최적화 문제를 풀 때 실제 공간이 어떻게 생겼는지에 대한 직관을 가지기는 어렵지만, 이러한 내용은 최적화 알고리즘이 직면할 수 있는 도전과제에 대한 더 나은 직관을 제공할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ac7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
